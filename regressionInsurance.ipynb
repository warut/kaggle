{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84896,"databundleVersionId":10305135,"sourceType":"competition"},{"sourceId":10240600,"sourceType":"datasetVersion","datasetId":6332864}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install -U feature-engine","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import catboost\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom catboost.utils import eval_metric\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Optuna objective function\ndef objective(trial):\n    params = {\n        #\"iterations\": 3000,    # OPtuna example not specify iteration\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1),\n        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n    }\n\n    model = CatBoostRegressor(**params, silent=True,random_seed=51)\n    model.fit(train_pool,verbose=0,eval_set=val_pool)\n    y_pred = model.predict(val_pool)\n    #rmse = mean_squared_error(y_val, predictions, squared=False)\n    return eval_metric(val_pool.get_label(),y_pred,'RMSE')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e12/test.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train['StartYM']=pd.to_datetime(df_train['Policy Start Date']).dt.strftime('%Y-%m')\ndf_train['StartY']=pd.to_datetime(df_train['Policy Start Date']).dt.strftime('%Y')\ndf_test['StartY']=pd.to_datetime(df_test['Policy Start Date']).dt.strftime('%Y')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train['StartYM'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['StartY'].value_counts().reset_index().sort_values(by=['StartY'],ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[df_train['Premium Amount']<120].groupby('StartY')['Premium Amount'].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test['Annual Income'].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[df_train['Annual Income']<200]['Credit Score'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test[df_test['Annual Income']<200]['Annual Income'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#only Age, Anuual Income,Credit Score are number. The rest are category\nnumeric_columns=df_train.select_dtypes(include=np.number).columns\nnumeric_columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"object_columns=df_train.select_dtypes(include=object).columns\nobject_columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#transform target\ndf_train['Label']=np.log1p(df_train['Premium Amount'])\ndf_train['Label'].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check Na credit score and premium amount\n# There a lot of missing score with a lot of premium no different with having creditscor\ndf_train[df_train['Credit Score'].notna()].groupby('Premium Amount').size().reset_index(name='count').assign(total=lambda x:x['Premium Amount']*x['count']).groupby('count')['total'].sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from feature_engine.transformation import YeoJohnsonTransformer\n\n#tf = YeoJohnsonTransformer(variables = ['Annual Income', 'Label'])\n\n#tf.fit(df_train.dropna())\n#tf.lambda_dict_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train_tf=tf.transform(df_train.dropna())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[df_train['Premium Amount']<120].loc[:,['Annual Income','Credit Score']].sort_values(ascending=True,by=['Annual Income']).head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[df_train['Premium Amount']<120]['Credit Score'].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['Credit Score'].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# change fillna from mean to mode to get less effect from outlier\n# Ana=df_train['Age'].mode()[0]\n# Aina=df_train['Annual Income'].mode()[0]\n# Ndna=0\n# Hsna=df_train['Health Score'].mode()[0]\n# Pcna=0\n# Vana=0 #just impute with 0\n# Csna=df_train['Credit Score'].mode()[0]\n# Idna=0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_train['Age'].fillna(Ana,inplace=True)\n# df_train['Annual Income'].fillna(Aina,inplace=True)\n# df_train['Number of Dependents'].fillna(Ndna,inplace=True)\n# df_train['Health Score'].fillna(Hsna,inplace=True)\n# df_train['Previous Claims'].fillna(Pcna,inplace=True)\n# df_train['Vehicle Age'].fillna(Vana,inplace=True)\n# df_train['Credit Score'].fillna(Csna,inplace=True)\n# df_train['Insurance Duration'].fillna(Idna,inplace=True)\n\n\n#Ana=df_test['Age'].mean()\n#Aina=df_test['Annual Income'].mean()\n#Ndna=0\n#Hsna=df_test['Health Score'].mean()\n#Pcna=0\n#Vana=0 #just impute with 0\n#Csna=df_test['Credit Score'].mean()\n#Idna=0\n\n# df_test['Age'].fillna(Ana,inplace=True)\n# df_test['Annual Income'].fillna(Aina,inplace=True)\n# df_test['Number of Dependents'].fillna(Ndna,inplace=True)\n# df_test['Health Score'].fillna(Hsna,inplace=True)\n# df_test['Previous Claims'].fillna(Pcna,inplace=True)\n# df_test['Vehicle Age'].fillna(Vana,inplace=True)\n# df_test['Credit Score'].fillna(Csna,inplace=True)\n# df_test['Insurance Duration'].fillna(Idna,inplace=True)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom catboost import CatBoostRegressor\n# Initialize data\n\ntrain_data = [[1., 4., 5., np.nan],\n              [4., 5., 6., 7.],\n              [30., 40., 50., 60.]]\n\neval_data = [[2., 4., 6., 8.],\n             [1., 4., 50., 60.]]\n\ntrain_labels = [10., 20., 30.]\n# Initialize CatBoostRegressor\nmodel = CatBoostRegressor(iterations=2,\n                          learning_rate=1,\n                          depth=2)\n# Fit model\nmodel.fit(train_data, train_labels)\n# Get predictions\npreds = model.predict(eval_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[df_train['Age'].isna()].index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['Occupation'].fillna('Unknown',inplace=True)\ndf_train['Marital Status'].fillna('Unknown',inplace=True)\ndf_train['Customer Feedback'].fillna('Unknown',inplace=True)\n\ndf_test['Occupation'].fillna('Unknown',inplace=True)\ndf_test['Marital Status'].fillna('Unknown',inplace=True)\ndf_test['Customer Feedback'].fillna('Unknown',inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cat_features=numeric_columns.drop(['id','Age','Annual Income','Credit Score','Health Score','Premium Amount']).union(object_columns)\ncat_features=object_columns\ncat_features.to_list()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#change cat columns datatype to astype int\ndf_train[cat_features.intersection(numeric_columns)]=df_train[cat_features.intersection(numeric_columns)].astype('Int64')\n\n#text_features = cat_features.remove('Vehicle Age')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#change cat columns datatype to int astype\ndf_test[cat_features.intersection(numeric_columns)]=df_test[cat_features.intersection(numeric_columns)].astype('Int64')\n\n#text_features = cat_features.remove('Vehicle Age')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#custom loss function but will not be able to optimization with it so better transform target instead\n#def rmsle_loss(y_true, y_pred):\n#    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n#Also use exp to transform the prediction\n#predictions = np.expm1(model.predict(X_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train.drop(['id','Annual Income','Customer Feedback','Exercise Frequency','Premium Amount','group Age','Label'],axis=1).columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train2 = pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv')\n#df_train2=df_train2.dropna()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#nonadata = pd.concat([df_train2['Credit Score'],df_train2['Health Score']],axis=1)\n#nonadata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#nonadata.describe()\n#from sklearn.preprocessing import StandardScaler, RobustScaler\n\n#standard_scaler=StandardScaler()\n#scalenonadata=standard_scaler.fit_transform(nonadata)\n\n#robust_scaler=RobustScaler()\n#scalenonadata=robust_scaler.fit_transform(nonadata)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#nonadata=pd.DataFrame(scalenonadata,columns=['Credit Score','Health Score'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train2['Label'] = np.log1p(df_train2['Premium Amount'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = df_train.drop(['id','Premium Amount','Policy Start Date','Label'],axis=1) \ncat_features=cat_features.intersection(data.columns)\ncat_features=cat_features.difference(['Credit Score','Health Score','Annual Income'])\n#text_features=text_features.intersection(data.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[cat_features]=df_train[cat_features].astype('category')\ndf_test[cat_features]=df_test[cat_features].astype('category')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import *\n\nX_train,x_val,Y_train,y_val = train_test_split(df_train.drop(['id','Premium Amount','Policy Start Date','Label'],axis=1),df_train['Label'],test_size=0.2,random_state=11)\ntrain_pool=Pool(data=X_train,\n                label=Y_train,\n                cat_features=cat_features.to_list())\nval_pool=Pool(data=x_val,\n               label=y_val,\n               cat_features=cat_features.to_list())\nX_test = df_test.drop(['id','Policy Start Date'],axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calc_test_quality(train_pool, val_pool, **kwargs):\n    model = CatBoostRegressor(**kwargs, random_seed=11)\n    model.fit(train_pool, verbose=0, eval_set=val_pool)\n    y_pred = model.predict(val_pool)\n    return eval_metric(val_pool.get_label(), y_pred, 'RMSE'), model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from optuna.samplers import TPESampler\n\nsampler = TPESampler(seed=123)\nstudy = optuna.create_study(direction='minimize', sampler=sampler)\nstudy.optimize(objective, n_trials=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params={'learning_rate': 0.07717313793943478,\n            'depth': 10, \n            'l2_leaf_reg': 6.673721788075379,\n            'subsample': 0.6913428855236023, \n            'colsample_bylevel': 0.8273248556818064,\n            'min_data_in_leaf': 8}\n#Best is trial 17 with value: 1.0496756348707192\n\nmetriclist, model = calc_test_quality(train_pool,val_pool,**best_params)\nmodel.save_model('optuna_tune_model')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicts = model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicts_original_scale = np.expm1(predicts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#round int\ntemp=pd.concat([df_test['id'],pd.DataFrame(np.rint(predicts_original_scale),columns=['Premium Amount'])],axis=1).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#not round int\ntemp2=pd.concat([df_test['id'],pd.DataFrame(predicts_original_scale.astype(int),columns=['Premium Amount'])],axis=1).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp.to_csv('submissionX.csv',index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp2.to_csv('submission_not_round.csv',index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip sub.zip submissionX.csv","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}